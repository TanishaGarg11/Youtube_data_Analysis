# -*- coding: utf-8 -*-
"""Untitled55.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j-cZo-Auf5cOgHwbTuErCE9fX7zsrEZd
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# Set random seed for reproducibility
np.random.seed(42)

print("="*70)
print("CREATING REALISTIC YOUTUBE PERFORMANCE DATASET (50 VIDEOS)")
print("="*70)


# 50 realistic YouTube video titles
titles = [
    "How I Made $10,000 in 30 Days (Step by Step)",
    "Python Tutorial for Beginners - Full Course [2025]",
    "I Tried Dropshipping for 30 Days - Honest Results",
    "The TRUTH About AI That Nobody Tells You",
    "Why 99% of People FAIL at Passive Income",
    "Day in My Life as a Software Engineer at Google",
    "This ONE Habit Changed My Life Forever",
    "React Hooks Complete Guide - 2025 Edition",
    "I Spent $5000 on Amazon FBA - Here's What Happened",
    "The Problem With Social Media (You Need to Hear This)",
    "My $50K/Month Business - Behind the Scenes",
    "You're Using ChatGPT WRONG - Do This Instead",
    "Complete Web Development Roadmap 2025",
    "I Quit My 6-Figure Job to Start This Business",
    "Why I Deleted All My Social Media",
    "Build a Full Stack App in One Video",
    "The Side Hustle That Pays $100/Hour",
    "5 AI Tools That Will Replace Your Job in 2025",
    "My YouTube Studio Setup Tour ($5K Budget)",
    "How to Get 1000 Subscribers FAST in 2025",
    "I Tested 10 Productivity Apps - Here's The Winner",
    "Machine Learning Explained in 15 Minutes",
    "Your Content Isn't Growing - Here's Why",
    "Building a $100K SaaS from Scratch",
    "The Reality of Being Self-Employed Nobody Shows",
    "Docker Crash Course - Beginner to Advanced",
    "This Marketing Strategy Got Me 100K Followers",
    "What I Wish I Knew Before Starting a Business",
    "My Minimalist Desk Setup 2025",
    "How to Build an AI App from Scratch",
    "I Failed for 3 Years Before This Breakthrough",
    "JavaScript Advanced Concepts Every Dev Needs",
    "Why I Invested $50K in Crypto (Honest Review)",
    "The Best Business Advice I Ever Received",
    "Coding Interview Prep - Top 20 Questions",
    "How I Automate My Entire YouTube Channel",
    "This Mistake Cost Me $30,000 (Don't Do This)",
    "Full Stack Developer Course - 10 Hour Tutorial",
    "The REAL Cost of Being a Content Creator",
    "Scaling to $1M Revenue - What I Learned",
    "I Tried Every AI Tool - Top 5 Revealed",
    "YouTube Algorithm Changed - Do This NOW",
    "Building a Mobile App - Complete Tutorial",
    "Why I Left California for Dubai",
    "My Favorite Tech Tools for Productivity",
    "This Side Hustle Pays $5K/Month (Beginner Friendly)",
    "What YouTubers Don't Tell You About Money",
    "REST API Tutorial - Node.js & Express",
    "My Biggest Business Failure and Lessons Learned",
    "Get Your First 10K Followers - Proven Strategy"
]

# 50 detailed thumbnail descriptions
thumbnails = [
    "Shocked face + '$10K' in yellow + money raining background",
    "Code editor screenshot + 'Python' logo + clean minimalist design",
    "Split screen before/after + red arrow + earnings graph",
    "Face pointing at camera + 'TRUTH' in bold red + AI graphics",
    "Red X over '99%' text + frustrated expression",
    "Office desk wide shot + Google logo visible + laptop screen",
    "Transformation split image + bright yellow background",
    "React logo + hooks diagram + dark blue tech aesthetic",
    "Amazon boxes + shocked face + '$5000' text overlay",
    "Silhouette with phone + moody dark lighting + warning colors",
    "Money graphics + revenue chart + celebration pose",
    "ChatGPT logo + red 'WRONG' stamp + correct way arrow",
    "Roadmap infographic + multiple tech logos + clean layout",
    "Corporate office + resignation letter + happy expression",
    "Social media logos with red X + peaceful face",
    "Coding screen + full project visible + progress timeline",
    "Calculator showing '$100' + clock icon + excited face",
    "Robot imagery + worried face + '2025' text prominent",
    "Wide desk setup shot + RGB lighting + expensive gear",
    "1000 subscriber milestone graphic + growth chart + pointing",
    "Grid of 10 app icons + winner crown on one + ratings",
    "Neural network diagram + brain graphics + '15 min' timer",
    "Declining graph + frustrated expression + 'FIX NOW' text",
    "Revenue dashboard + $100K highlighted + laptop screen",
    "Tired face + messy desk + honest expression + dark tone",
    "Docker whale logo + terminal screenshot + code snippets",
    "Exponential growth graph + '100K' text + celebration",
    "Regretful expression + calendar with X marks + warning sign",
    "Clean desk aesthetic + plants + white background + minimal tech",
    "AI interface + laptop coding + futuristic blue theme",
    "Crying emoji + '3 YEARS' text + breakthrough moment split",
    "Complex code snippet + highlighter effect + pro developer vibe",
    "Bitcoin logo + portfolio graph + serious expression + '$50K'",
    "Mentor/advice aesthetic + notepad + wisdom quote overlay",
    "Whiteboard with algorithms + professional attire + clean design",
    "Workflow automation diagram + relaxed coffee pose + calm colors",
    "Face palm + '$30K' in red + sad emoji + warning colors",
    "Full IDE screenshot + file explorer + '10 HOURS' badge",
    "Expensive equipment + price tags floating + shocked reaction",
    "$1M milestone graphic + scaling chart + business professional look",
    "5 AI tool logos + ranking numbers + comparison grid + winner highlight",
    "YouTube logo + algorithm graph + urgent red background + 'NOW'",
    "Phone mockups + app interface + code background + modern design",
    "Dubai skyline + airplane + passport + adventure vibe",
    "Flat lay of tech gadgets + organized aesthetic + productivity theme",
    "$5K' prominent + simple task visual + 'EASY' badge + beginner friendly",
    "Money bags + YouTuber behind camera + hidden truth theme + dark",
    "API diagram + Postman interface + Node.js logo + code editor",
    "Failure to success arrow + lessons text + reflective expression",
    "10K follower milestone + strategy blueprint + growth chart + excited"
]

# Upload time slots
upload_times = [
    "Morning (6-9am)", "Midday (11am-1pm)", "Afternoon (2-4pm)",
    "Evening (5-7pm)", "Night (8-10pm)"
]

# Channel distribution: 30 yours, 10 each competitor
channels = ["Your Channel"] * 30 + ["Competitor A"] * 10 + ["Competitor B"] * 10


data = []

for i in range(50):
    # Basic info
    channel = channels[i]
    title = titles[i]
    thumbnail = thumbnails[i]
    upload_time = np.random.choice(upload_times, p=[0.15, 0.15, 0.20, 0.35, 0.15])  # Evening most common

    # Analyze title/thumbnail characteristics
    has_numbers = any(char.isdigit() for char in title[:20])
    is_tutorial = any(word in title.lower() for word in ['tutorial', 'guide', 'course', 'explained'])
    is_clickbait = any(word in title.lower() for word in ['truth', 'secret', 'nobody', 'fail', '$'])
    is_personal = any(word in title.lower() for word in ['i tried', 'i spent', 'my ', 'i quit'])
    has_face = "face" in thumbnail.lower()
    has_money = "$" in thumbnail or "money" in thumbnail.lower()

    # Set base performance by channel
    if channel == "Your Channel":
        base_views = np.random.uniform(8000, 45000)
        base_ctr = np.random.uniform(4.0, 9.5)
        base_retention = np.random.uniform(38, 68)
    elif channel == "Competitor A":
        base_views = np.random.uniform(50000, 120000)
        base_ctr = np.random.uniform(8.5, 13.5)
        base_retention = np.random.uniform(52, 78)
    else:  # Competitor B
        base_views = np.random.uniform(45000, 110000)
        base_ctr = np.random.uniform(8.0, 12.5)
        base_retention = np.random.uniform(50, 75)

    # Apply realistic correlations
    if is_clickbait:
        base_ctr *= 1.45
        base_views *= 1.55
        base_retention *= 0.82  # Clickbait disappoints viewers

    if is_tutorial:
        base_retention *= 1.35
        base_views *= 0.68
        base_ctr *= 0.80

    if is_personal:
        base_ctr *= 1.25
        base_views *= 1.30

    if has_face and has_money:
        base_ctr *= 1.40
        base_views *= 1.25
    elif has_face:
        base_ctr *= 1.20
        base_views *= 1.12

    if has_numbers:
        base_ctr *= 1.15

    # Upload time impact
    time_multipliers = {
        "Morning (6-9am)": 1.15,
        "Midday (11am-1pm)": 0.70,
        "Afternoon (2-4pm)": 0.95,
        "Evening (5-7pm)": 1.40,
        "Night (8-10pm)": 1.05
    }
    base_views *= time_multipliers[upload_time]

    # Calculate final metrics
    views = int(base_views)
    ctr = round(min(base_ctr, 16.0), 1)
    avg_retention = round(min(base_retention, 88.0), 1)

    # Duration (tutorials longer)
    if is_tutorial:
        duration = np.random.choice([28, 32, 38, 42, 48, 55, 62])
    else:
        duration = np.random.choice([8, 10, 12, 14, 16, 18, 22])

    # Watch time
    watch_time_hours = int((views * duration * (avg_retention / 100)) / 60)

    # Realistic retention curve (drops over time)
    ret_30s = round(min(avg_retention + np.random.uniform(8, 18), 96), 1)
    ret_1min = round(avg_retention + np.random.uniform(3, 10), 1)
    ret_2min = round(avg_retention + np.random.uniform(-2, 4), 1)
    ret_5min = round(avg_retention - np.random.uniform(5, 12), 1)
    ret_10min = round(avg_retention - np.random.uniform(12, 20), 1)
    ret_end = round(max(avg_retention - np.random.uniform(18, 32), 20), 1)

    # Upload date (last 90 days)
    days_ago = np.random.randint(1, 91)
    upload_date = (datetime.now() - timedelta(days=days_ago)).strftime("%Y-%m-%d")

    # Engagement metrics
    likes = int(views * np.random.uniform(0.025, 0.075))
    comments = int(views * np.random.uniform(0.008, 0.025))
    shares = int(views * np.random.uniform(0.002, 0.008))

    # Add to dataset
    data.append({
        'Video_ID': f'VID_{i+1:03d}',
        'Channel': channel,
        'Title': title,
        'Thumbnail_Description': thumbnail,
        'Upload_Date': upload_date,
        'Upload_Time': upload_time,
        'Duration_Minutes': duration,
        'Views': views,
        'CTR_Percent': ctr,
        'Avg_Retention_Percent': avg_retention,
        'Watch_Time_Hours': watch_time_hours,
        'Retention_30sec': ret_30s,
        'Retention_1min': ret_1min,
        'Retention_2min': ret_2min,
        'Retention_5min': ret_5min,
        'Retention_10min': ret_10min,
        'Retention_End': ret_end,
        'Likes': likes,
        'Comments': comments,
        'Shares': shares
    })



df = pd.DataFrame(data)
df.to_csv('youtube_performance_dataset.csv', index=False)
df.to_excel('youtube_performance_dataset.xlsx', index=False, engine='openpyxl')

print("\n DATASET CREATED SUCCESSFULLY!\n")
print(f"Total Videos: {len(df)}")
print(f"   • Your Channel: {len(df[df['Channel']=='Your Channel'])} videos")
print(f"   • Competitor A: {len(df[df['Channel']=='Competitor A'])} videos")
print(f"   • Competitor B: {len(df[df['Channel']=='Competitor B'])} videos\n")

print(" Files Saved:")
print("   • youtube_performance_dataset.csv")
print("   • youtube_performance_dataset.xlsx\n")

print("="*70)
print("DATASET PREVIEW - First 5 Videos")
print("="*70)
preview_cols = ['Video_ID', 'Channel', 'Views', 'CTR_Percent', 'Avg_Retention_Percent']
print(df[preview_cols].head().to_string(index=False))

print("\n" + "="*70)
print("SAMPLE VIDEO DETAILS (3 Random Examples)")
print("="*70)

samples = df.sample(3)
for idx, row in samples.iterrows():
    print(f"\n {row['Video_ID']}: {row['Title']}")
    print(f"   Channel: {row['Channel']}")
    print(f"   Thumbnail: {row['Thumbnail_Description']}")
    print(f"   Upload: {row['Upload_Date']} at {row['Upload_Time']}")
    print(f"   Duration: {row['Duration_Minutes']} minutes")
    print(f"   Performance:")
    print(f"      • Views: {row['Views']:,}")
    print(f"      • CTR: {row['CTR_Percent']}%")
    print(f"      • Avg Retention: {row['Avg_Retention_Percent']}%")
    print(f"      • Watch Time: {row['Watch_Time_Hours']:,} hours")
    print(f"   Retention Curve:")
    print(f"      • 30 sec: {row['Retention_30sec']}%")
    print(f"      • 1 min: {row['Retention_1min']}%")
    print(f"      • 5 min: {row['Retention_5min']}%")
    print(f"      • End: {row['Retention_End']}%")
    print(f"   Engagement:")
    print(f"      • {row['Likes']:,} likes | {row['Comments']:,} comments | {row['Shares']:,} shares")

print("\n" + "="*70)
print("DATASET STATISTICS")
print("="*70)
stats = df[['Views', 'CTR_Percent', 'Avg_Retention_Percent', 'Watch_Time_Hours']].describe()
print(stats.round(1).to_string())

print("\n" + "="*70)
print("CHANNEL COMPARISON")
print("="*70)
comparison = df.groupby('Channel')[['Views', 'CTR_Percent', 'Avg_Retention_Percent', 'Watch_Time_Hours']].mean().round(1)
print(comparison.to_string())

print("\n" + "="*70)
print(" DATASET FEATURES INCLUDED:")
print("="*70)
print("✓ Views (realistic range 8K - 120K)")
print("✓ Watch Time (calculated from views × duration × retention)")
print("✓ CTR % (4% - 13.5% realistic range)")
print("✓ Retention Graph Points (30sec, 1min, 2min, 5min, 10min, end)")
print("✓ 50 Unique Video Titles (realistic YouTube style)")
print("✓ 50 Detailed Thumbnail Descriptions")
print("✓ Upload Times (Morning, Midday, Afternoon, Evening, Night)")
print("✓ 3 Channels (Your Channel + 2 Competitors)")
print("✓ Realistic Correlations:")
print("   • Clickbait → Higher CTR, More Views, Lower Retention")
print("   • Tutorials → Higher Retention, Fewer Views")
print("   • Evening Uploads → 40% More Views")
print("   • Face Thumbnails → Better CTR")
print("="*70)
print("\nReady for analysis in Python, Excel, or Power BI!")
print("="*70)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_csv('youtube_performance_dataset.csv')

print("="*80)
print("YOUTUBE PERFORMANCE ANALYSIS - FINDING WHAT WORKS & WHAT DOESN'T")
print("="*80)

# ============================================
# PART 1: WHAT'S WORKING? (Positive Patterns)
# ============================================

print("\n" + "="*76)
print("PART 1: WHAT'S WORKING? (Things That Drive Performance)")
print("="*80 + "\n")

# Analysis 1: Channel Performance Gap
print(" ANALYSIS 1: Your Channel vs Competitors - The Reality Check")
print("-" * 80)

channel_stats = df.groupby('Channel').agg({
    'Views': ['mean', 'median', 'max'],
    'CTR_Percent': 'mean',
    'Avg_Retention_Percent': 'mean',
    'Watch_Time_Hours': 'mean'
}).round(1)

your_channel = df[df['Channel'] == 'Your Channel']
competitors = df[df['Channel'] != 'Your Channel']

print("\nAverage Performance:")
print(f"  Your Channel:    {your_channel['Views'].mean():>8,.0f} views | {your_channel['CTR_Percent'].mean():.1f}% CTR | {your_channel['Avg_Retention_Percent'].mean():.1f}% retention")
print(f"  Competitor A:    {df[df['Channel']=='Competitor A']['Views'].mean():>8,.0f} views | {df[df['Channel']=='Competitor A']['CTR_Percent'].mean():.1f}% CTR | {df[df['Channel']=='Competitor A']['Avg_Retention_Percent'].mean():.1f}% retention")
print(f"  Competitor B:    {df[df['Channel']=='Competitor B']['Views'].mean():>8,.0f} views | {df[df['Channel']=='Competitor B']['CTR_Percent'].mean():.1f}% CTR | {df[df['Channel']=='Competitor B']['Avg_Retention_Percent'].mean():.1f}% retention")

view_gap = ((competitors['Views'].mean() - your_channel['Views'].mean()) / your_channel['Views'].mean() * 100)
ctr_gap = ((competitors['CTR_Percent'].mean() - your_channel['CTR_Percent'].mean()) / your_channel['CTR_Percent'].mean() * 100)

print(f"\n Key Finding:")
print(f"   Competitors are getting {view_gap:.0f}% more views on average")
print(f"   Their CTR is {ctr_gap:.0f}% higher than yours")
print(f"   BUT - your retention is competitive ({your_channel['Avg_Retention_Percent'].mean():.1f}% vs {competitors['Avg_Retention_Percent'].mean():.1f}%)")
print(f"\n    This means: Your CONTENT is good (retention proves it)")
print(f"      But your PACKAGING (title/thumbnail) needs work (low CTR)")

# Analysis 2: Upload Time Impact
print("\n\n ANALYSIS 2: When You Upload Actually Matters")
print("-" * 80)

time_performance = df[df['Channel']=='Your Channel'].groupby('Upload_Time').agg({
    'Views': ['mean', 'count'],
    'CTR_Percent': 'mean'
}).round(0)

time_performance.columns = ['Avg_Views', 'Video_Count', 'Avg_CTR']
time_performance = time_performance.sort_values('Avg_Views', ascending=False)

print("\nPerformance by Upload Time (Your Channel):")
for idx, row in time_performance.iterrows():
    print(f"  {idx:25s} → {row['Avg_Views']:>6,.0f} views (n={int(row['Video_Count'])})")

best_time = time_performance.index[0]
worst_time = time_performance.index[-1]
time_diff = ((time_performance.loc[best_time, 'Avg_Views'] - time_performance.loc[worst_time, 'Avg_Views']) / time_performance.loc[worst_time, 'Avg_Views'] * 100)

print(f"\n Key Finding:")
print(f"   {best_time} uploads perform {time_diff:.0f}% better than {worst_time}")
print(f"\n    Why this happens:")
print(f"      • Evening = peak YouTube traffic (people home from work/school)")
print(f"      • Algorithm gives initial boost to videos uploaded during high-traffic times")
print(f"      • More early views = Algorithm thinks 'this is good' = pushes it harder")
print(f"      • Midday = everyone's busy = fewer people online = video DOA")

# Analysis 3: Thumbnail Strategy
print("\n ANALYSIS 3: Thumbnail Elements That Actually Get Clicks")
print("-" * 80)

# Categorize thumbnails
df['Has_Face'] = df['Thumbnail_Description'].str.contains('face', case=False)
df['Has_Money_Graphics'] = df['Thumbnail_Description'].str.contains('\$|money', case=False)
df['Has_Emotions'] = df['Thumbnail_Description'].str.contains('shocked|excited|frustrated|worried|sad|happy|celebration', case=False)

your_data = df[df['Channel']=='Your Channel']

thumbnail_analysis = pd.DataFrame({
    'Face + Money': your_data[your_data['Has_Face'] & your_data['Has_Money_Graphics']]['CTR_Percent'].mean(),
    'Face Only': your_data[your_data['Has_Face'] & ~your_data['Has_Money_Graphics']]['CTR_Percent'].mean(),
    'No Face': your_data[~your_data['Has_Face']]['CTR_Percent'].mean(),
    'With Emotion': your_data[your_data['Has_Emotions']]['CTR_Percent'].mean(),
    'No Emotion': your_data[~your_data['Has_Emotions']]['CTR_Percent'].mean()
}, index=['CTR']).T.round(1)

print("\nCTR by Thumbnail Elements (Your Channel):")
for element, ctr in thumbnail_analysis.itertuples():
    print(f"  {element:20s} → {ctr:.1f}% CTR")

print(f"\n Key Finding:")
print(f"   Thumbnails with BOTH face + money graphics get highest CTR")
print(f"   Emotional expressions boost CTR significantly")
print(f"\n    Why this works:")
print(f"      • Faces = our brains are wired to look at faces first")
print(f"      • Money graphics = universal curiosity trigger")
print(f"      • Emotions = create immediate connection ('I feel that too!')")
print(f"      • Text-only = boring, gets ignored in feed of flashy thumbnails")

# ============================================
# PART 2: WHAT'S FAILING? (Negative Patterns)
# ============================================

print("\n\n"  + "="*76)
print("PART 2: WHAT'S FAILING? (Things Hurting Your Performance)")
print("="*80 + "\n")

# Analysis 4: The Retention Drop Problem
print(" ANALYSIS 4: Where Are You Losing Viewers?")
print("-" * 80)

retention_cols = ['Retention_30sec', 'Retention_1min', 'Retention_2min', 'Retention_5min', 'Retention_10min', 'Retention_End']
avg_retention_curve = your_data[retention_cols].mean().round(1)

print("\nAverage Retention Curve (Your Channel):")
print(f"  At 30 seconds:  {avg_retention_curve['Retention_30sec']:.1f}% still watching")
print(f"  At 1 minute:    {avg_retention_curve['Retention_1min']:.1f}% still watching (lost {avg_retention_curve['Retention_30sec'] - avg_retention_curve['Retention_1min']:.1f}%)")
print(f"  At 2 minutes:   {avg_retention_curve['Retention_2min']:.1f}% still watching (lost {avg_retention_curve['Retention_1min'] - avg_retention_curve['Retention_2min']:.1f}%)")
print(f"  At 5 minutes:   {avg_retention_curve['Retention_5min']:.1f}% still watching (lost {avg_retention_curve['Retention_2min'] - avg_retention_curve['Retention_5min']:.1f}%)")

first_30_drop = avg_retention_curve['Retention_30sec'] - avg_retention_curve['Retention_1min']
two_to_five_drop = avg_retention_curve['Retention_2min'] - avg_retention_curve['Retention_5min']

print(f"\n Key Finding:")
if first_30_drop > 10:
    print(f"   BIG PROBLEM: Losing {first_30_drop:.1f}% in first 30 seconds")
    print(f"   This is BAD - means your intro isn't hooking people")
else:
    print(f"   First 30 seconds are decent (only {first_30_drop:.1f}% drop)")

print(f"   Bigger drop between 2-5 min mark ({two_to_five_drop:.1f}% leave)")
print(f"\n   Why this happens:")
print(f"      • First 30 sec = You promised something (in title) but haven't delivered yet")
print(f"      • People are impatient - if you waste time, they leave")
print(f"      • 2-5 min mark = Classic 'middle slump' - content gets boring/repetitive")
print(f"      • Fix: Get to the point FAST. No long intros. Cut the fluff.")

# Analysis 5: Title Types That Underperform
print("\n\n ANALYSIS 5: Which Video Types Are Underperforming?")
print("-" * 80)

# Categorize videos
your_data['Is_Tutorial'] = your_data['Title'].str.contains('Tutorial|Course|Guide|Explained', case=False)
your_data['Is_Clickbait'] = your_data['Title'].str.contains('TRUTH|FAIL|NOBODY|SECRET|\$', case=False)
your_data['Is_Personal'] = your_data['Title'].str.contains('I Tried|I Spent|I Quit|My ', case=False)

video_type_perf = pd.DataFrame({
    'Tutorial': [
        your_data[your_data['Is_Tutorial']]['Views'].mean(),
        your_data[your_data['Is_Tutorial']]['CTR_Percent'].mean(),
        your_data[your_data['Is_Tutorial']]['Avg_Retention_Percent'].mean()
    ],
    'Clickbait': [
        your_data[your_data['Is_Clickbait']]['Views'].mean(),
        your_data[your_data['Is_Clickbait']]['CTR_Percent'].mean(),
        your_data[your_data['Is_Clickbait']]['Avg_Retention_Percent'].mean()
    ],
    'Personal Story': [
        your_data[your_data['Is_Personal']]['Views'].mean(),
        your_data[your_data['Is_Personal']]['CTR_Percent'].mean(),
        your_data[your_data['Is_Personal']]['Avg_Retention_Percent'].mean()
    ]
}, index=['Avg Views', 'Avg CTR', 'Avg Retention']).T.round(1)

print("\nPerformance by Video Type:")
print(video_type_perf.to_string())

tutorial_views = video_type_perf.loc['Tutorial', 'Avg Views']
tutorial_retention = video_type_perf.loc['Tutorial', 'Avg Retention']
clickbait_views = video_type_perf.loc['Clickbait', 'Avg Views']
clickbait_retention = video_type_perf.loc['Clickbait', 'Avg Retention']

print(f"\n Key Finding:")
print(f"   Tutorials have GREAT retention ({tutorial_retention:.1f}%) but LOW views ({tutorial_views:,.0f})")
print(f"   Clickbait has HIGH views ({clickbait_views:,.0f}) but TERRIBLE retention ({clickbait_retention:.1f}%)")
print(f"\n    The problem:")
print(f"      • Tutorial titles are boring ('Complete Python Tutorial')")
print(f"      • Nobody gets excited about the word 'Tutorial'")
print(f"      • Your content is actually good (retention proves it)")
print(f"      • But you're hiding good content behind boring packaging")
print(f"\n    The clickbait problem:")
print(f"      • Title promises the moon ('SECRET to $10K!')")
print(f"      • Content doesn't deliver → people feel tricked → leave")
print(f"      • You get the click but lose trust + retention")

# Analysis 6: Duration Sweet Spot
print("\n\n ANALYSIS 6: Are Your Videos Too Long or Too Short?")
print("-" * 80)

your_data['Duration_Category'] = pd.cut(your_data['Duration_Minutes'],
                                         bins=[0, 12, 20, 100],
                                         labels=['Short (8-12min)', 'Medium (12-20min)', 'Long (20min+)'])

duration_perf = your_data.groupby('Duration_Category').agg({
    'Views': 'mean',
    'Avg_Retention_Percent': 'mean',
    'Watch_Time_Hours': 'mean'
}).round(0)

print("\nPerformance by Video Length:")
print(duration_perf.to_string())

print(f"\n Key Finding:")
long_retention = your_data[your_data['Duration_Minutes'] > 20]['Avg_Retention_Percent'].mean()
short_retention = your_data[your_data['Duration_Minutes'] <= 12]['Avg_Retention_Percent'].mean()

if long_retention < short_retention - 5:
    print(f"   Longer videos ({long_retention:.1f}% retention) struggle vs shorter ones ({short_retention:.1f}%)")
    print(f"\n    Why this happens:")
    print(f"      • People have short attention spans")
    print(f"      • Longer videos need MUCH better pacing to keep attention")
    print(f"      • You're probably adding filler content to hit length")
    print(f"      • Better to make tight 10min video than fluffy 30min one")

# ============================================
# PART 3: WHY IS THIS HAPPENING? (Root Causes)
# ============================================

print("\n\n"  + "="*76)
print("PART 3: ROOT CAUSE ANALYSIS - Why These Patterns Exist")
print("="*80 + "\n")

print(" ROOT CAUSE #1: The Discovery Problem (Low CTR)")
print("-" * 80)
print("Your average CTR is lower than competitors. This means:")
print("  • People SEE your videos in search/recommended")
print("  • But they don't CLICK on them")
print("  • Problem = Your title/thumbnail isn't interesting enough")
print("\nWhy competitors win:")
print("  ✓ They use faces in thumbnails (you sometimes don't)")
print("  ✓ They use emotion words (TRUTH, NOBODY, SECRET)")
print("  ✓ They show numbers/money (creates specific curiosity)")
print("\nYour mistake:")
print("  ✗ Too many 'safe' titles ('Tutorial', 'Guide', 'Explained')")
print("  ✗ Some thumbnails lack faces or emotion")
print("  ✗ Not leveraging curiosity gaps enough")

print("\n\n ROOT CAUSE #2: The Timing Problem")
print("-" * 80)
print("You're uploading at wrong times, missing peak traffic:")
print("  • Midday uploads = Dead zone = Nobody online")
print("  • Evening uploads = Rush hour = Everyone's watching")
print("\nAlgorithm mechanics:")
print("  1. Video uploads → YouTube shows it to small test audience")
print("  2. If they engage quickly → Algorithm thinks 'this is hot' → Shows to more people")
print("  3. If nobody's online → No engagement → Algorithm thinks 'this is bad' → Buries it")
print("\nUpload time is free 40% boost you're not taking advantage of")

print("\n\n ROOT CAUSE #3: The Content Packaging Paradox")
print("-" * 80)
print("You have a weird situation:")
print(f"  • Your retention is good ({your_channel['Avg_Retention_Percent'].mean():.1f}%) = Content quality is there")
print(f"  • Your CTR is low ({your_channel['CTR_Percent'].mean():.1f}%) = Packaging sucks")
print("\nThis means:")
print("  → People who DO watch love your videos")
print("  → But most people never give you a chance")
print("  → You're leaving 2-3x potential views on the table")
print("\nIt's like having an amazing restaurant with terrible signage")
print("The food is great, but nobody knows to come in")

print("\n\n ROOT CAUSE #4: Tutorial Content Dilemma")
print("-" * 80)
tutorial_count = your_data['Is_Tutorial'].sum()
print(f"You make {tutorial_count} tutorial videos. They have:")
print(f"  • Best retention (people who watch, REALLY watch)")
print(f"  • Worst views (hardly anyone clicks)")
print("\nThe problem with 'Tutorial' in title:")
print("  ✗ It screams 'BORING and LONG'")
print("  ✗ Only people who already decided to learn will click")
print("  ✗ You're not creating curiosity")
print("\nCompare these:")
print("  'Complete Python Tutorial for Beginners'")
print("     → Sounds like homework. Who wants homework?")
print("  'I Learned Python in 30 Days - Here's What Nobody Tells You'")
print("     → Curiosity + personal story + hidden knowledge = Click!")
print("\nSame content, different packaging, 2-3x more views")

print("\n\n" + "="*80)
print(" CONCLUSION: The Action Plan")
print("="*80)
print("\n1. FIX CTR (Biggest Impact):")
print("   → Add faces to every thumbnail")
print("   → Use emotion/money graphics")
print("   → Rewrite tutorial titles with curiosity hooks")
print("\n2. FIX TIMING (Easy Win):")
print("   → Stop midday uploads")
print("   → Upload 5-7pm consistently")
print("\n3. FIX INTRO (Quick Fix):")
print("   → Cut first 30 seconds to bare minimum")
print("   → Deliver on title promise immediately")
print("   → No fluff, get to point fast")
print("\n4. MAINTAIN QUALITY:")
print("   → Your retention is good, don't change content quality")
print("   → Just improve the packaging around it")
print("\n" + "="*80)

plt.figure(figsize=(8,5))
plt.scatter(df['CTR_Percent'], df['Views'], alpha=0.6)
plt.xlabel('CTR (%)')
plt.ylabel('Views')
plt.title('CTR vs Views: Packaging Impact')
plt.show()

time_views = df[df['Channel']=='Your Channel'].groupby('Upload_Time')['Views'].mean()

plt.figure(figsize=(8,5))
time_views.plot(kind='bar')
plt.xlabel('Upload Time')
plt.ylabel('Average Views')
plt.title('Upload Time vs Views')
plt.show()

ret_cols = ['Retention_30sec','Retention_1min','Retention_2min','Retention_5min','Retention_10min','Retention_End']
avg_ret = your_data[ret_cols].mean()

plt.figure(figsize=(8,5))
plt.plot(ret_cols, avg_ret, marker='o')
plt.ylabel('Retention (%)')
plt.title('Average Viewer Retention Curve')
plt.show()